{
  "version": 4,
  "terraform_version": "0.12.20",
  "serial": 10,
  "lineage": "199f1982-a7a0-6aa3-435d-716433925ac8",
  "outputs": {},
  "resources": [
    {
      "module": "module.jupyterhub",
      "mode": "managed",
      "type": "kubernetes_config_map",
      "name": "main",
      "provider": "provider.kubernetes",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "binary_data": null,
            "data": {
              "jupyterhub_config.py": "# Expected Environment Variables\n#  - PROXY_API_SERVICE_HOST\n#  - PROXY_API_SERVICE_PORT\n#  - POD_NAMESPACE\n#  - HUB_SERVICE_HOST\n#  - HUB_SERVICE_PORT\n\n# based on zero to jupyterhub\n# https://github.com/jupyterhub/zero-to-jupyterhub-k8s/blob/master/jupyterhub/files/hub/jupyterhub_config.py\nimport os\n\n# Configure JupyterHub to use the curl backend for making HTTP requests,\n# rather than the pure-python implementations. The default one starts\n# being too slow to make a large number of requests to the proxy API\n# at the rate required.\nAsyncHTTPClient.configure(\"tornado.curl_httpclient.CurlAsyncHTTPClient\")\n\nc.JupyterHub.spawner_class = 'kubespawner.KubeSpawner'\n\n# Connect to a proxy running in a different pod\nc.ConfigurableHTTPProxy.api_url = 'http://{}:{}'.format(os.environ['PROXY_API_SERVICE_HOST'], int(os.environ['PROXY_API_SERVICE_PORT']))\nc.ConfigurableHTTPProxy.should_start = False\n\n# Do not shut down user pods when hub is restarted\nc.JupyterHub.cleanup_servers = False\n\n# Check that the proxy has routes appropriately setup\nc.JupyterHub.last_activity_interval = 60\n\n# Don't wait at all before redirecting a spawning user to the progress page\nc.JupyterHub.tornado_settings = {\n    'slow_spawn_timeout': 0,\n}\n\n# Configure persistent sqlite jupyterhub database\nc.JupyterHub.db_url = \"sqlite:///jupyterhub.sqlite\"\n\n# Set jupyterhub proxy ip/hostname\nc.JupyterHub.ip = os.environ['PROXY_PUBLIC_SERVICE_HOST']\nc.JupyterHub.port = int(os.environ['PROXY_PUBLIC_SERVICE_PORT'])\n\n# the hub should listen on all interfaces, so the proxy can access it\nc.JupyterHub.hub_ip = '0.0.0.0'\n\n# Set default namespace for pods to be launched as\nc.KubeSpawner.namespace = os.environ.get('POD_NAMESPACE', 'default')\n\n# Gives spawned containers access to the API of the hub\nc.JupyterHub.hub_connect_ip = os.environ['HUB_SERVICE_HOST']\nc.JupyterHub.hub_connect_port = int(os.environ['HUB_SERVICE_PORT'])\n\nc.JupyterHub.services = []\n\n\n\n\nHUB_USER_MAPPING = {{ cookiecutter.security.users }}\nQHUB_GROUP_MAPPING = {{ cookiecutter.security.groups }}\nQHUB_PROFILES = {{ cookiecutter.profiles.jupyterlab }}\n\ndef qhub_generate_nss_files():\n    passwd = []\n    passwd_format = '{username}:x:{uid}:{gid}:{username}:/home/jovyan:/bin/bash'\n    for username, config in QHUB_USER_MAPPING.items():\n        uid = config['uid']\n        gid = QHUB_GROUP_MAPPING[config['primary_group']]['gid']\n        passwd.append(passwd_format.format(username=username, uid=uid, gid=gid))\n\n    group = []\n    group_format = '{groupname}:x:{gid}:'\n    for groupname, config in QHUB_GROUP_MAPPING.items():\n        gid = config['gid']\n        group.append(group_format.format(groupname=groupname, gid=gid))\n\n    return '\\n'.join(passwd), '\\n'.join(group)\n\n\ndef qhub_list_admins(users):\n    return [k for k,v in users.items() if v['primary_group'] == 'admin']\n\n\ndef qhub_list_users(users):\n    return [k for k,v in users.items() if v['primary_group'] != 'admin']\n\n\ndef qhub_list_user_groups(username):\n    user = QHUB_USER_MAPPING[username]\n    return set([user['primary_group']] + user.get('secondary_groups', []))\n\n\ndef qhub_configure_profile(username, safe_username, profile):\n    user = QHUB_USER_MAPPING[username]\n    uid = user['uid']\n    primary_gid = QHUB_GROUP_MAPPING[user['primary_group']]['gid']\n    secondary_gids = [QHUB_GROUP_MAPPING[_]['gid'] for _ in user.get('secondary_groups', [])]\n\n    profile['kubespawner_override']['environment'] = {\n       'LD_PRELOAD': 'libnss_wrapper.so',\n       'NSS_WRAPPER_PASSWD': '/tmp/passwd',\n       'NSS_WRAPPER_GROUP': '/tmp/group',\n       'HOME': '/home/jovyan',\n    }\n\n    passwd, group = qhub_generate_nss_files()\n    profile['kubespawner_override']['lifecycle_hooks'] = {\n        \"postStart\": {\n            \"exec\": {\n                \"command\": [\"/bin/sh\", \"-c\", (\n                     \"echo '{passwd}' \u003e /tmp/passwd \u0026\u0026 \"\n                     \"echo '{group}' \u003e /tmp/group \u0026\u0026 \"\n                     \"ln -sfn /home/shared /home/jovyan/shared\"\n                ).format(passwd=passwd, group=group)]\n            }\n        }\n    }\n\n    profile['kubespawner_override']['init_containers'] = [\n        {\n             \"name\": \"init-nfs\",\n             \"image\": \"busybox:1.31\",\n             \"command\": [\"sh\", \"-c\", ' \u0026\u0026 '.join([\n                  \"mkdir -p /mnt/home/{username}\",\n                  \"chmod 700 /mnt/home/{username}\",\n                  \"chown {uid}:{primary_gid} /mnt/home/{username}\",\n                  \"mkdir -p /mnt/home/shared\",\n                  \"chmod 777 /mnt/home/shared\"\n             ] + [\"mkdir -p /mnt/home/shared/{groupname} \u0026\u0026 chmod 770 /mnt/home/shared/{groupname} \u0026\u0026 chown 0:{gid} /mnt/home/shared/{groupname}\".format(groupname=groupname, gid=config['gid']) for groupname, config in QHUB_GROUP_MAPPING.items()]).format(username=safe_username, uid=uid, primary_gid=primary_gid)],\n             \"securityContext\": {\"runAsUser\": 0},\n             \"volumeMounts\": [{\"mountPath\": \"/mnt\", \"name\": \"home\"}]\n        }\n    ]\n\n    profile['kubespawner_override']['uid'] = uid\n    profile['kubespawner_override']['gid'] = primary_gid\n    profile['kubespawner_override']['supplemental_gids'] = secondary_gids\n    profile['kubespawner_override']['fs_gid'] = primary_gid\n    return profile\n\ndef qhub_list_available_profiles(username):\n    import escapism\n    import string\n    safe_chars = set(string.ascii_lowercase + string.digits)\n    safe_username = escapism.escape(username, safe=safe_chars, escape_char='-').lower()\n\n    exclude_keys = {'users', 'groups'}\n\n    groups = qhub_list_user_groups(username)\n\n    available_profiles = []\n    for profile in QHUB_PROFILES:\n        filtered_profile = qhub_configure_profile(username, safe_username, {k: v for k,v in profile.items() if k not in exclude_keys})\n\n        if 'users' in profile:\n            if username in profile['users']:\n                available_profiles.append(filtered_profile)\n        elif 'groups' in profile:\n            if len(groups \u0026 set(profile['groups'])) != 0:\n                available_profiles.append(filtered_profile)\n        else:\n            available_profiles.append(filtered_profile)\n\n    return available_profiles\n\nc.JupyterHub.admin_access = True\nc.Authenticator.admin_users = qhub_list_admins(QHUB_USER_MAPPING)\nc.Authenticator.whitelist = qhub_list_users(QHUB_USER_MAPPING)\n\nasync def custom_options_form(self):\n    self.profile_list = qhub_list_available_profiles(self.user.name)\n\n    # Let KubeSpawner inspect profile_list and decide what to return\n    return self._options_form_default()\n\n\nc.KubeSpawner.options_form = custom_options_form\nc.LocalProcessSpawner.shell_cmd = ['bash', '-l', '-c']\n"
            },
            "id": "dev/terraform-qhub-jupyterhub-config",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 0,
                "labels": null,
                "name": "terraform-qhub-jupyterhub-config",
                "namespace": "dev",
                "resource_version": "34275",
                "self_link": "/api/v1/namespaces/dev/configmaps/terraform-qhub-jupyterhub-config",
                "uid": "fedbfb96-aa6e-49d9-aebf-f76c7e6d6a26"
              }
            ]
          },
          "private": "bnVsbA=="
        }
      ]
    },
    {
      "module": "module.dask-gateway",
      "mode": "managed",
      "type": "kubernetes_config_map",
      "name": "main",
      "provider": "provider.kubernetes",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "binary_data": null,
            "data": {
              "daskgateway_config.py": "import os\nimport json\n\n_PROPERTIES = json.loads({{- $values | toJson | quote }})\n\ndef get_property(key, default=None):\n    \"\"\"Read a property from the configured helm values.\"\"\"\n    value = _PROPERTIES\n    for key2 in key.split(\".\"):\n        if not isinstance(value, dict) or key2 not in value:\n            return default\n        value = value[key2]\n    return value\n\nc.DaskGateway.log_level = \"{{ .Values.gateway.loglevel }}\"\n\n# Configure addresses\nc.DaskGateway.address = \":8000\"\nc.KubeBackend.api_url = 'http://{{ include \"dask-gateway.apiName\" . }}.{{ .Release.Namespace }}:8000/api'\n\n# Configure the backend\nc.DaskGateway.backend_class = \"dask_gateway_server.backends.kubernetes.KubeBackend\"\nc.KubeBackend.gateway_instance = \"{{ include \"dask-gateway.fullname\" . }}\"\n\n# Configure the dask cluster image\nimage_name = get_property(\"gateway.backend.image.name\")\nif image_name:\n    image_tag = get_property(\"gateway.backend.image.tag\")\n    c.KubeClusterConfig.image = (\n        \"%s:%s\" % (image_name, image_tag) if image_tag else image_name\n    )\n\n# Forward dask cluster configuration\nfor field, prop_name in [\n    # Scheduler config\n    (\"scheduler_cores\", \"scheduler.cores.request\"),\n    (\"scheduler_cores_limit\", \"scheduler.cores.limit\"),\n    (\"scheduler_memory\", \"scheduler.memory.request\"),\n    (\"scheduler_memory_limit\", \"scheduler.memory.limit\"),\n    (\"scheduler_extra_container_config\", \"scheduler.extraContainerConfig\"),\n    (\"scheduler_extra_pod_config\", \"scheduler.extraPodConfig\"),\n    # Worker config\n    (\"worker_cores\", \"worker.cores.request\"),\n    (\"worker_cores_limit\", \"worker.cores.limit\"),\n    (\"worker_memory\", \"worker.memory.request\"),\n    (\"worker_memory_limit\", \"worker.memory.limit\"),\n    (\"worker_extra_container_config\", \"worker.extraContainerConfig\"),\n    (\"worker_extra_pod_config\", \"worker.extraPodConfig\"),\n    # Additional fields\n    (\"image_pull_policy\", \"image.pullPolicy\"),\n    (\"environment\", \"environment\"),\n    (\"namespace\", \"namespace\"),\n]:\n    value = get_property(\"gateway.backend.\" + prop_name)\n    if value is not None:\n        setattr(c.KubeClusterConfig, field, value)\n\n# Authentication\nauth_type = get_property(\"gateway.auth.type\")\nif auth_type == \"simple\":\n    c.DaskGateway.authenticator_class = \"dask_gateway_server.auth.SimpleAuthenticator\"\n    password = get_property(\"gateway.auth.simple.password\")\n    if password is not None:\n        c.SimpleAuthenticator.password = password\nelif auth_type == \"kerberos\":\n    c.DaskGateway.authenticator_class = \"dask_gateway_server.auth.KerberosAuthenticator\"\n    keytab = get_property(\"gateway.auth.kerberos.keytab\")\n    if keytab is not None:\n        c.KerberosAuthenticator.keytab = keytab\nelif auth_type == \"jupyterhub\":\n    c.DaskGateway.authenticator_class = \"dask_gateway_server.auth.JupyterHubAuthenticator\"\n    api_url = get_property(\"gateway.auth.jupyterhub.apiUrl\")\n    if api_url is None:\n        try:\n            api_url = \"http://{HUB_SERVICE_HOST}:{HUB_SERVICE_PORT}/hub/api\".format(**os.environ)\n        except Exception:\n            raise ValueError(\n                \"Failed to infer JupyterHub API url from environment, \"\n                \"please specify `gateway.auth.jupyterhub.apiUrl` in \"\n                \"your config file\"\n            )\n    c.DaskGateway.JupyterHubAuthenticator.jupyterhub_api_url = api_url\nelif auth_type == \"custom\":\n    auth_cls = get_property(\"gateway.auth.custom.class\")\n    c.DaskGateway.authenticator_class = auth_cls\n    auth_cls_name = auth_cls.rsplit('.', 1)[-1]\n    auth_config = c[auth_cls_name]\n    auth_config.update(get_property(\"gateway.auth.custom.config\") or {})\nelse:\n    raise ValueError(\"Unknown authenticator type %r\" % auth_type)\n"
            },
            "id": "dev/terraform-qhub-daskgateway-config",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 0,
                "labels": null,
                "name": "terraform-qhub-daskgateway-config",
                "namespace": "dev",
                "resource_version": "34276",
                "self_link": "/api/v1/namespaces/dev/configmaps/terraform-qhub-daskgateway-config",
                "uid": "c4db5c91-6169-423d-a2ef-562a67e81f12"
              }
            ]
          },
          "private": "bnVsbA=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "main",
      "provider": "provider.kubernetes",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "dev",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 0,
                "labels": null,
                "name": "dev",
                "resource_version": "34269",
                "self_link": "/api/v1/namespaces/dev",
                "uid": "2ee91224-f3cd-408d-a17c-0c5319d82227"
              }
            ],
            "timeouts": null
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    }
  ]
}
